{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source for analysis\n",
    "text = \"\"\"\n",
    "Yesterday,\n",
    "All my troubles seemed so far away,\n",
    "Now it looks as though they're here to stay\n",
    "Oh I believe in yesterday\n",
    "Suddenly,\n",
    "I'm not half the man I used to be\n",
    "There's a shadow hanging over me\n",
    "Oh yesterday came suddenly\n",
    "Why she had to go\n",
    "I don't know, she wouldn't say\n",
    "I said something wrong\n",
    "Now I'm long for yesterday\n",
    "Yesterday,\n",
    "Love was such an easy game to play\n",
    "Now I need a place to hide away\n",
    "Oh I believe in yesterday\n",
    "Why she had to go\n",
    "I don't know, she wouldn't say\n",
    "I said something wrong\n",
    "Now I'm long for yesterday\n",
    "Yesterday,\n",
    "Love was such an easy game to play\n",
    "Now I need a place to hide away\n",
    "Oh I believe in yesterday.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yesterday', 'all', 'my', 'troubles', 'seemed', 'so', 'far', 'away', 'now', 'it', 'looks', 'as', 'though', 'they', 're', 'here', 'to', 'stay', 'oh', 'i', 'believe', 'in', 'yesterday', 'suddenly', 'i', 'm', 'not', 'half', 'the', 'man', 'i', 'used', 'to', 'be', 'there', 's', 'a', 'shadow', 'hanging', 'over', 'me', 'oh', 'yesterday', 'came', 'suddenly', 'why', 'she', 'had', 'to', 'go', 'i', 'don', 't', 'know', 'she', 'wouldn', 't', 'say', 'i', 'said', 'something', 'wrong', 'now', 'i', 'm', 'long', 'for', 'yesterday', 'yesterday', 'love', 'was', 'such', 'an', 'easy', 'game', 'to', 'play', 'now', 'i', 'need', 'a', 'place', 'to', 'hide', 'away', 'oh', 'i', 'believe', 'in', 'yesterday', 'why', 'she', 'had', 'to', 'go', 'i', 'don', 't', 'know', 'she', 'wouldn', 't', 'say', 'i', 'said', 'something', 'wrong', 'now', 'i', 'm', 'long', 'for', 'yesterday', 'yesterday', 'love', 'was', 'such', 'an', 'easy', 'game', 'to', 'play', 'now', 'i', 'need', 'a', 'place', 'to', 'hide', 'away', 'oh', 'i', 'believe', 'in', 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "def preprocess_text(text):\n",
    "    cleaned = re.sub(r'\\W+', ' ', text).lower()\n",
    "    tokenized = word_tokenize(cleaned)\n",
    "    return tokenized\n",
    "tokens = preprocess_text(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yesterday', 'troubles', 'seemed', 'far', 'away', 'looks', 'though', 'stay', 'oh', 'believe', 'yesterday', 'suddenly', 'half', 'man', 'used', 'shadow', 'hanging', 'oh', 'yesterday', 'came', 'suddenly', 'go', 'know', 'say', 'said', 'something', 'wrong', 'long', 'yesterday', 'yesterday', 'love', 'easy', 'game', 'play', 'need', 'place', 'hide', 'away', 'oh', 'believe', 'yesterday', 'go', 'know', 'say', 'said', 'something', 'wrong', 'long', 'yesterday', 'yesterday', 'love', 'easy', 'game', 'play', 'need', 'place', 'hide', 'away', 'oh', 'believe', 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "#removing stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def no_stopwords(text):\n",
    "    clean_text = [word for word in tokens if word not in stop_words]\n",
    "    return clean_text\n",
    "print(no_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yesterday', 'troubles', 'seemed', 'far', 'away', 'looks', 'though', 'stay', 'oh', 'believe', 'yesterday', 'suddenly', 'half', 'man', 'used', 'shadow', 'hanging', 'oh', 'yesterday', 'came', 'suddenly', 'go', 'know', 'say', 'said', 'something', 'wrong', 'long', 'yesterday', 'yesterday', 'love', 'easy', 'game', 'play', 'need', 'place', 'hide', 'away', 'oh', 'believe', 'yesterday', 'go', 'know', 'say', 'said', 'something', 'wrong', 'long', 'yesterday', 'yesterday', 'love', 'easy', 'game', 'play', 'need', 'place', 'hide', 'away', 'oh', 'believe', 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "tokens = no_stopwords(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequently used words (Bigrams):\n",
      "[(('oh', 'believe'), 3), (('believe', 'yesterday'), 3), (('go', 'know'), 2), (('know', 'say'), 2), (('say', 'said'), 2)]\n",
      "\n",
      "Most frequently used words (Bag-of-words):\n",
      "[('yesterday', 9), ('oh', 4), ('away', 3), ('believe', 3), ('suddenly', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams:\n",
    "bigrams_num = ngrams(tokens, 2)\n",
    "bigrams = Counter(bigrams_num)\n",
    "print(\"Most frequently used words (Bigrams):\")\n",
    "print(bigrams.most_common(5))\n",
    "\n",
    "# Bag-of-Words:\n",
    "bag_of_words = Counter(tokens)\n",
    "print(\"\\nMost frequently used words (Bag-of-words):\")\n",
    "five_top = Counter.most_common(bag_of_words, 5)\n",
    "print(five_top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
